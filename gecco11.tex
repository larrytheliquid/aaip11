\documentclass{acm_proc_article-sp}
\usepackage[mathletters]{ucs}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{tipa,textcomp}

\begin{document}

\title{Verified Stack-Based Genetic Programming\\
via Dependent Types}

\numberofauthors{1}
\author{
\alignauthor Larry Diehl\\
       \email{larrytheliquid@gmail.com}
}

\maketitle
\begin{abstract}
Abstract here.
\end{abstract}

\category{D.1.1}{Programming Techniques}{Applicative (Functional) Programming}
\category{I.2.2}{Artificial Intelligence}{Automatic Programming}[program synthesis, program verification]

\terms{Languages, Reliability, Verification}

\keywords{stack-based gp, linear gp, dependent types, purely functional programming, formal methods}

\section{Introduction}

Genetic Programming (GP) as a field began by using the meta-language
(Lisp) to directly represent candidate solutions for a problem. This is primarily due
to the easy manipulation of parse trees and built-in evaluation
function over them. Naturally, a lot of GP's early and prominent work
was dominated by dynamic language implementations, clever avoidance of
\cite{to:do} type-issues during evolution, and tree-based program terms
for the algorithm to operate on.

Since then, there has been work on using type-awareness to inform the
different stages of the algorithm \cite{to:do} (population generation,
genetic operators, etc.) There has also been plenty of separate work
on alternative representations (linear, graph, grammar-based, etc.)

Significant advances have been made investigating how variations of
the basic algorithm affect properties like search space, fitness
gradients, and overall performance. One area that has not seen as much
exploration is the correctness of the implementation of a GP
algorithm. GP involves significant complexity, as it must maintain a
population of program terms, update the population across generations
with term-manipulating genetic operators, evaluation of individuals,
selection, TODO.

The most frequently used method to compare the performance of a
particular GP implementation is to compute basic statistics about
things like fitness scores, size of terms, TODO and see how they
change as algorithm stages progress. This often takes the form of
looking at such tabulated, graphed, or otherwise visualized data and
drawing conclusions about how evolution must have done this or that to
explain interesting portions of the data. Seeing what evolution is
buying us is, after all, the point.

That leads us to a problem that we would like to address. Namely,
being sure that the behavior of the algorithm is what we expect. Given
the complexity of these algorithsm, it would be very unfortunate,
although not unimaginable, to have bugs in implementation that cause
certain phenomena to occur in the data analyzed in the end. We would
like to avoid researchers drawing conclusions from implementation
mistakes and attributing and propagating evolutionary explanations for
them.

In harmony with this goal is making sure evolution is used only where
necessary, rather than taking a swiss army knife approach of forcing
evolution solve all aspects of a problem. One
related GP problem is that of ill-formed programs. Typical
dynamic-type inspired solutions either \cite{koza:onlygood}, assign a minimal fitness to
ill-formed programs, or treat failing operations as
NOOP's
\footnote{In a stack-based language, a runtime failure can act like a
  NOOP by continuing execution with an unmodified stack state. However,
  tree-based languages do not have a simple way to return nothing}.
The first approach does not scale up to problems involving more
complex types that are not related in meaningful ways for the purpose
of conversions. The second approach puts more of a burden on evolution, and the third
leads to bloat (a problem evolutionary algorithms already have enough
of.)

Instead, we will use static-typing inspired approaches featured in
strongly typed GP \cite{montana:strongtree, tchernev:forthcross} that make algorithmic
modifications to constrain the search space that evolution must
explore. Further, to fit with our other goal of avoiding
implementation mistakes, operating on a simple structure that still
has ample opportunity for useful program recombination is
desirable. Although tree structures are the most common GP term
representation, functions designed to manipulate them are not as
straightforward as those on list/linear structures. Tchernev
\cite{tchernev:forthcross, tchernev:crossmethods} has shown how simple
methods for type-safe linear crossover can be competitive with those
of subtree crossover. 1-dimensional flat structures such as lists are
intuitively simpler than nested trees, although more technically this
can be understood as operations on lists forming a monoid
\cite{to:do}. Additionally, functions operating on list monads have
several well-understood and mathematically-backed results in the
domain of permutations that are useful in a GP setting.

In essence, we would like to come up with a list of invariants that
the implementation of a GP algorithm should uphold in order to make us
more confident in explanations of emergent phenomena in terms of
evolution. A programming language that is capable of succinctly
expressing our desired properties, and has the semantics to be able to
check them, is desireable. For basic hygene, we want to use a purely
functional language (the most popular example being Haskell
\cite{to:do}). The complexity of algorithm requires several
interacting pieces, decisions depending on randomness, the
manipulation of terms, and updating a population. An implementation in
an impure language leaves many an opportunity for mistakes in the
interaction of various side affecting operations. Conversely, a pure
settings allows for a more structured, modular approach, to GP that
explicitly represents side effects via monads. Simulation of the side
effects in question are already mature and well-understood.

Secondly, the typical GP program must deal with things like catching
exceptions produced by failing programs, and assigning them low
fitness. The random generation of programs can also produce programs
that fail to terminate or take a long time to terminate. The halting
problem \cite{to:do} tells us that we cannot distinguish between the
two, but it would useful to handle the two cases differently
(e.g. giving a low fitness to the former but allowing the latter to
complete running). Although though Haskell is a pure language, it is
also a partial language. When using a partial meta-language, it is
possible to conflate problems having to do with exceptions and
termination in the meta-language implementation, with those observed
in object-language. Consequently, we seek a language that is both pure
and total.

In a certain sense, Hindley-Milner based languages that are both pure
and total just shift errors from being classified as runtime errors to
being classified as logic errors. This is because part of totality is
for a function to be coverage complete in its case analysis. For
example, a function that is designed to only work on some cases of an
argument must wrap its output in a failure-simulating monad
(e.g. Maybe). Enough nested functions passing around such simulated
failure can lead to sloppy programming that fails too much in one
place, or returns nonsense but type-correct values in
others. Furthermore, we need to be able express more complex GP
domain-specific invariants (such as type-correct crossover) that are
not afforded to us by purity or totality alone. This finally leads us
to the class of languages suitable for the task at hand, namely
dependently typed programming languages.

In addition to being pure and total, languages with dependent types
are characterized by the property that labeled dependencies can exist
at the type level of programs. Moreover, the typical distinction
between the kinds of programs expressible at the level of values and
at the level of types is no longer. In other words, arbitrarily
complex functions can be used in type signatures in order to constrain
or otherwise express the kind of data that a function operates on.

\section{Stack Languages}

In stack-based languages \cite{to:do} there is no
distinction between values and functions. Instead, each syntactic
element is referred to as a "word". Every word can be modeled as a
function which takes the previous stack state as a value and returns
the subsequent, possibly altered, state. Consider for example a
small word language in the boolean domain, made up of \texttt{true},
\texttt{false}, \texttt{and}, \texttt{or} , and \texttt{not}. A word
such as \texttt{true} that would typically be considered as a value
has no requirements on the input stack, and merely return the input
stack plus a boolean value of true pushed on top. On the other
hand, \texttt{and} requires the input stack to have at least two elements,
which is pops off in order to push their logical conjunction
back. It should be pointed out that unlike in tree-based grammars, a
previously pushed value may get used by an operation later in the
program. To reiterate, each word takes the entire global stack state
as input and returns the entire stack state as output. TODO

In a monotypic language, a simple static type system emerges which
assigns to each word a natural number representing the required input
stack length, and a second number representing the output stack
length. A sequence of such words forms a stack program, for which an
aggregate input/output pair can be computed. One can think of this
pair as a number representing how large of a stack is
\textit{consumed}, and another representing the size of the
\textit{produced} stack... or alternatively function arity which
indicates the change of a size-indexed global variable.

\section{Intro to Dependent Types}

For purposes of pedagogy, we will first consider how to represent a
population of terms/programs in a typical non-dependent functional
programming style.

\subsection{Non-Dependent Types}

First let's create a new type representing the possible words for an
to be used for some evolutionary problem.

\begin{verbatim}
  data Word : Set where
    true false not and or : Word
\end{verbatim}

This simple example language is intended to operate on the boolean domain using
well-known constants and functions. Of course a stack program is not
merely a single word, but a sequence of them that we would like to
execute in order. The familiar cons-based list can serve as a
container for several words, so let us type it out.

\begin{verbatim}
  data List (A : Set) : Set where
    []  : List A
    _::_ : A → List A → List A

  Term : Set
  Term = List Word
\end{verbatim}

Notice in particular the \texttt{A : Set} part of the list
type. \texttt{Set} is the type of types in Agda, and the \texttt{A} is
a label that acts like a variable, but at the level of type
signatures. In other words, we have created a polymorphic list type
which is parameterized by what kind of data it can
contain. \texttt{Term} is a specific instantiation of lists that can
hold the \texttt{Word}s of our example language. Below are some
examples of programs we can now represent.

\begin{verbatim}
  identity : Term
  identity = not :: not :: []

  anotherTrue : Term
  anotherTrue = not :: not :: true :: []

  nand : Term
  nand = not :: and :: []
\end{verbatim}

GP requires us to work on not one but a collection of several terms,
referred to as the \textbf{population}. Normally, this might be
represented as a list of lists.

\begin{verbatim}
  Population : Set
  Population = List Term
\end{verbatim}

While the type above is certainly functional, it leaves room for
error. This brings us to our first example of preserving some GP
invariant with the help of dependent types. Namely, the population
that GP acts upon is expected to be a certain size, and it should stay
that size as GP progresses from one generation to the next. Given the
sum complexity due to initialization, selection, and genetic
operators, it would not be surprising if a GP implementation had a bug
that caused the population to be bigger or smaller than expected
at some point in the run. Population size of course affects search
space, so conclusions drawn from GP run data that was affected by a
population size bug would be incorrect.

\subsection{Dependent Types}

In the dependently typed world, an easy and effective way to ensure
that some invariant is held is to create a type that can only possibly
construct values that satisfy said invariant. In our case we would
like the population size to be some exact natural number that we specify at the
beginning of the run. This brings us to one of the canonical examples
of a dependent type, the vector. We have already seen how the list
type takes a parameter to achieve polymorphism. Vectors take an
additional parameter representing their length.

\begin{verbatim}
  data Vec (A : Set) : ℕ → Set where
    []  : Vec A zero
    _::_ : ∀ {n} → A → Vec A n
      → Vec A (suc n)

  Population : ℕ → Set
  Population n = Vec Term n
\end{verbatim}

The empty vector has a constant length of \texttt{zero}. The length of a vector
produced by cons is the \texttt{suc}cessor of whatever the length of
the tail is. Given such an inductive definition of a type, the natural
number index of any given vector can be nothing but its length. Just
like our definition of \texttt{Term}, \texttt{Population} is just a
specific instantiation of a more general type (\texttt{Vec}).

As an example, here is a small population of the three terms presented
earlier.

\begin{verbatim}
  pop : Population 3
  pop = identity :: anotherTrue :: nand :: []
\end{verbatim}

Once again, note that the type requires a population of exactly three
terms. If we were to supply any more or less, a type error would occur at
compile time. Effectively we move checking of certain \textit{semantic}
properties of our program to compile time, meaning much less can go
wrong once a program can be run.
\footnote{In fact, the only thing
  that can go wrong are logic errors due to bad encodings by the
  programmer. Typical runtime errors due to non-termination or lack of
  coverage are disallowed by the compiler.}

%% lookup + mod next

\section{Blah}

We will begin with a slow introduction to dependent types by
considering the size of the population as a constant-size list
throughout all generations of program evolution. For example, consider
a GP program run that uses an population of size 200. During each
generation, the previous population must be used to generate the next
in some fashion (e.g. genetic operations after tournament selection,
elitism, or constant-size updating \cite{montana:strongtree}). We
intend that the size of the population in the first generation, the
subsequent generations, and the final generations remains
constant.

%% ample opportunity for giving credit of strange behavior (such as
%% "epihanies" \cite{to:do}) to evolution, when really the search space
%% was fundamentally altered at that point.

As such, we will first consider the introductory task of representing
a constant-size population as a parameter and return type of a
black-box function which calculates the next generation from the
previous. Because the language semantics already assure us purity and
totality, let us focus our attention on the type signature of such a
function to see what else we can know at compile time rather than
looking at runtime-specific implementation details.

%% Since 

We can see in TODO
that we have a polymorphic function from a list of some arbitrary type
to another list of the same type. Statically, however, the length of
either of lists is not known and could change arbitrarily. Compare
this with the type signature of the function in TODO which uses the
type of vectors rathers than lists. A vector is like a list, but has
an additional type-level parameter (called an "index"). This parameter
is a natural number, and represents the length of the list. Just as
the polymorphic parameter \texttt{A} ensures that the type of lists/vectors
does not vary between the input and output, the natural number
parameter \texttt{n} ensures that the length of the population remains
constant.

For greater understanding, we will show how the types of lists and
vectors are defined, and how their values can be used and misused. In
TODO we see the that a constructively defined list with an empty case
with no arguments, and a "cons" case which takes an argument of
polymorphic type \texttt{A}, as well as a previous list of the same
type as the resulting list. Note that Agda supports arbitrary unicode
characters such as \texttt{::} as identifiers, and underscores to
indicate where arguments go for prefix/infix/mixfix constructors or
functions. If we compare \texttt{List} with \texttt{Vec}, we notice
the aforementioned additional natural number index parameter. The
empty case is defined to be of length zero and, and the cons case
takes a vector of arbitrary length as an argument, and returns a
vector whose length is one greater (the successor). In essence, we
have a definition of vectors that contains their length merely by
construction. As such, one can be sure when speaking about vectors
that the natural number index indeed represents length, as there is no
way of constructing the term otherwise. TODO is simple and concise,
making it understandable and giving us confidence in the
length-preserving invariant we would like to enforce when generating
the population for the next generation.


\section{Conclusion}


\bibliographystyle{abbrv}
\bibliography{gecco11}

\end{document}
