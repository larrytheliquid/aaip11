\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage[mathletters]{ucs}
\usepackage{bbm}
\usepackage[utf8]{inputenc}

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter  % start of an individual contribution

\title{[DRAFT] Verified Stack-Based Genetic Programming\\
via Dependent Types}
% a short form should be given in case it is too long for the running head
\titlerunning{Verified Stack-Based GP via Dependent Types}

\author{Larry Diehl}

\institute{\url{http://github.com/larrytheliquid}}

\maketitle
\begin{abstract}
Genetic Programming (GP) can act as a powerful search tool for many
classes of problems. Much research has been done exploring the
effectiveness of  various term representations, genetic operators, and
techniques for intelligently navigating the search space by taking
type information into account. This paper explores the less trodden
road of formally capturing invariants normally assumed in GP
implementations. Dependently Typed Programming (DTP) extends the
type-level expressiveness normally available in functional programming
languages to arbitrary propositions in intuitionistic logic. We use
DTP to express and enforce \textit{semantic} invariants relevant to GP
at the level of types, with a special focus on type-safe crossover for
strongly typed stack-based GP. Given the complexity involved in GP
implementations and the potential for bugs, we hope to help
researchers avoid errorneously attributing evolutionary explanations
to GP run phenomena by using a verified implementation. 
\keywords{genetic programming, dependent types, functional
  programming, formal verification}
\end{abstract}

\section{Introduction}

While the earliest work in Genetic Programming used tree structures as
candidate solutions to a problem, many alternative representations
have been developed since (linear, graph, grammar-based, etc). The
goal of this work is not to come up with a novel GP algorithm with
respect to evolutionary performance, but rather give an example of a
non-trivial but verified and simple to understand GP implementation.

Flat linear structures are conceptually simpler than nested trees and
intimately familiar to functional programmers, yet still provide
competitive evolutionary results compared to tree representations
\cite{tchernev:crossmethods}. As such, we will concentrate on
developing a stack-based genetic programming algorithm.

After a general overview of stack languages and dependent types, the
structure of the paper will follow a common classification scheme for
GP:
\begin{itemize}
\item{\textbf{parameters:}} Starting with a non-dependently typed
  representation, we will see how to use standard affair dependent
  typing to ensure the population size parameter is adhered to.
\item{\textbf{representation:}} Next we will see how to modify our
  term representation to use precise dependent types, encoding arity
  information in the types of candidate programs.
\item{\textbf{evaluation function:}} Taking advantage of the host
  language's totality requirement, we'll see how easy it is to write
  an evaluation function for evolved terms that is assured to
  terminate and not otherwise diverge.
\item{\textbf{genetic operators:}} Next we will encode
  the property of transitivity into the types of functions related to
  crossover, ensuring that ill-typed programs never enter the
  population.
\item{\textbf{initialization procedure:}} Finally we will show a basic
  procedure to initialize our population, making sure to only randomly
  select programs that match the type signature of the goal program.
\end{itemize}

\subsection{Stack Languages}

In stack-based languages such as Forth \cite{kelly:forth} there is no
distinction between constants and procedures. Instead, each syntactic
element is referred to as a ``word''. Every word can be modeled as a
function which takes the previous stack state as a value and returns
the subsequent, possibly altered, state. Consider for example a
small word language in the boolean domain, consisting of \texttt{true},
\texttt{or}, and \texttt{and}. A word
such as \texttt{true} (that would typically be considered a constant)
has no requirements on the input stack, and merely returns the input
stack plus a boolean value of ``true'' pushed on top. On the other
hand, \texttt{and} requires the input stack to have at least two elements,
which it pops off in order to push their logical conjunction
back.

For monotypic languages like our example, simple typing rules
emerge which assign to each word a natural number representing the
required input stack length (the precondition), and a second number representing
the output stack length (the postcondition). A sequence of such words forms a stack
program, for which an aggregate input/output pair exists.

During genetic operations such as crossover, stack programs must be
manipulated in some manner to produce offspring for the next
generation. Tchnernev \cite{tchernev:forthcross} showed how to use arity
information related to the consumed/produced stack sizes to only
perform crossover at points that will produce well-typed
terms. Tchnernev \cite{tchernev:crossmethods} has documented many different
approaches to do this, but for simplicity of presentation we will use
1-point crossover.

\subsection{Dependent Types}

Dependently typed languages have the distinguishing characteristic
that arguments in type signatures may be assigned labels (similar to
variable names), to be used elsewhere in type signature to declare
\textit{dependencies} between types and values. This paper will use the
dependently typed programming language Agda \cite{norell:agdatut} for
all of its examples, but it should be possible to translate examples
to similar languages such as Epigram \cite{mcbride:epigram} or
Idris \cite{brady:idris}.

Agda is a purely functional language (the most popular example being
Haskell \cite{spj:haskell}), in which effectful code is made explicit via
types. This has the effect of making the implementation of pure algorithms
more understandable, and complicated reasoning required to trace side
effects can be isolated to a small corner of the final program.

At compile time, Agda programs must pass two checks to prove their
totality. Termination checking is accomplished by checking
for structurally decreasing recursive calls. Coverage checking is
accomplished by requiring that every type-correct value of a function's
arguments is accounted for in the function's definition.
Consequently, Agda programs do not fail to terminate
\footnote{Although Agda programs can succeed to not terminate via
  coinductive definition and corecursion, if controlled
  non-termination is what we want.}
or crash due to unexpected input. This meta-theoretical property of
our language is convenient if we wanted to model evolution of
partially defined programs, without having to worry confusing object
language partiality with host language partiality.

Finally, as a rule of thumb an Agda programmer forgets the traditional
distinction between what can be computed at compile time versus runtime. In
particular, any ``value level'' function can be used at the type level
as well.

\section{Parameters}

For purposes of pedagogy, we will first consider how to represent a
population of terms/programs in a typical non-dependent functional
programming style. Thereafter, we will extend the example to use
dependent types.
\footnote{For a complete and proper tutorial on dependently typed programming in Agda, see \cite{norell:agdatut}}

\subsection{Population List}

First let's create a new type representing the possible words to be
used for some evolutionary problem.

\begin{verbatim}
  data Word : Set where
    true not and : Word
\end{verbatim}

This simple example language is intended to operate on the boolean domain using
well-known constants and functions. Of course a stack program is not
merely a single word, but a sequence of them that we would like to
execute in order. The familiar cons-based list can serve as a
container for several words, so let us type it out.

\begin{verbatim}
  data List (A : Set) : Set where
    []  : List A
    _::_ : A → List A → List A

  Term : Set
  Term = List Word
\end{verbatim}

Notice in particular the \texttt{A : Set} part of the list
type. \texttt{Set} is the type of types in Agda, and \texttt{A} is
a label that acts like a variable, but at the level of type
signatures. In other words, we have created a polymorphic list type
which is parameterized by what kind of data it can
contain. \texttt{Term} is a specific instantiation of lists that can
hold the \texttt{Word}s of our example language. Below are some
examples of programs we can now represent.

\begin{verbatim}
  notNot : Term
  notNot = not :: not :: []

  anotherTrue : Term
  anotherTrue = not :: not :: true :: []

  nand : Term
  nand = not :: and :: []
\end{verbatim}

GP requires us to work on not one but a collection of several terms,
referred to as the \textbf{population}. Normally, this might be
represented as a list of lists of terms.

\begin{verbatim}
  Population : Set
  Population = List Term
\end{verbatim}

While the type above is certainly functional, it leaves room for
error. This brings us to our first example of preserving some GP
invariant with the help of dependent types. Namely, the population
that GP acts upon is expected to be a certain size, and it should stay
that size as GP progresses from one generation to the next. Given the
sum complexity due to initialization, selection, and genetic
operators, it would not be surprising if a GP implementation had a bug
that caused the population to be bigger or smaller than expected
at some point in the run. Population size of course affects search
space, so conclusions drawn from GP run data that was affected by a
population size bug would be incorrect.

\subsection{Population Vector}

In the dependently typed world, an easy and effective way to ensure
that some invariant is held is to create a type that can only possibly
construct values that satisfy said invariant
(``correctness-by-construction''). In our case we would
like the population size parameter to be some natural number
that we specify when configuring the run. This brings us to one of
the canonical examples of a dependent type, the vector. We have
already seen how the list type takes a parameter to achieve
polymorphism. Vectors take an additional parameter representing their
length.

\begin{verbatim}
  data Vec (A : Set) : ℕ → Set where
    []  : Vec A zero
    _::_ : {n : ℕ} → A → Vec A n →
      Vec A (suc n)

  Population : ℕ → Set
  Population n = Vec Term n
\end{verbatim}

The empty vector has a constant length of \texttt{zero}. The length of a vector
produced by cons is the \texttt{suc}cessor of whatever the length of
the tail is. Given such an inductive definition of a type, the natural
number index of any given vector can be nothing but its length. Just
like our definition of \texttt{Term}, \texttt{Population} is just a
specific instantiation of a more general type (\texttt{Vec}).

As an example, here is a small population of the three terms presented
earlier.

\begin{verbatim}
  pop : Population 3
  pop = notNot :: anotherTrue :: nand :: []
\end{verbatim}

Once again, note that the type requires a population of exactly three
terms. If we were to supply any more or less, a type error would occur at
compile time. Effectively we move checking of certain \textit{semantic}
properties of our program to compile time, meaning much less can go
wrong once a program can be run.
\footnote{In fact, the only thing
  that can go wrong are logic errors due to bad encodings by the
  programmer. Typical runtime errors due to non-termination or lack of
  coverage are disallowed by the compiler.}

Now that we've seen how to construct a dependent type, let's see how
a function operating on \texttt{Vec} can make use of its properties.
During selection, GP will need to retrieve a candidate program from
the population. An all too common error taught even at introductory
level programming is indexing outside the bounds of a container
structure. How might one prevent this error? Ideally the type of the
parameter used to lookup a member should have exactly as many values
as the length of our vector. This way, a bijection would exist between
the lookup index type and the vector positions.

\begin{verbatim}
  data Fin : ℕ → Set where
    zero : {n : ℕ} → Fin (suc n)
    suc  : {n : ℕ} → Fin n → Fin (suc n)

  lookup : {A : Set} {n : ℕ} →
    Fin n → Vec A n → A
  lookup    zero (x :: xs) = x
  lookup (suc i) (x :: xs) = lookup i xs
\end{verbatim}

The type of finite sets \texttt{Fin} has exactly \texttt{n} possible
values for any \texttt{Fin n}. In the \texttt{lookup} function the
natural number index is shared between the finite set and vector
parameters. The effect of this sharing is that every finite set
argument has exactly as many possible constructions as the length of
the vector argument, statically preventing any index out of bounds
errors from occuring. Since our \texttt{Population} is merely a
specific kind of vector, we are able to use the safe \texttt{lookup}
when defining a function for the selection process.

\section{Representation}

In the previous section we represented the terms in our population as
unadorened lists of words. In order to perform type-safe crossover in
a manner described by \cite{tchernev:forthcross}, the type of our
terms will need to be more telling.

\subsection{Typing Derivation}

It should come as no suprise that when we implement a type-safe
version of crossover that we will need to pay close attention to the
types of terms we are manipulating. Just as \texttt{Vec} had an extra
natural number parameter for its length, we desire a \texttt{Term}
type with an extra parameter for the size of the consumed/input stack, and
another for the size of the produced/output stack.

Before showing a generalized list-like \texttt{Term} type for arbitary
languages, we will take a look at a more traditional embedding of a
typing relation into Agda.

\begin{verbatim}
  data Term (inp : ℕ) : ℕ → Set where
    []   : Term inp inp
    true : {out : ℕ} → Term inp      out  → Term m (1 + out)
    not  : {out : ℕ} → Term inp (1 + out) → Term m (1 + out)
    and  : {out : ℕ} → Term inp (2 + out) → Term m (1 + out)
\end{verbatim}

Recall that the first parameter is the consumed stack size and the second
is the produced stack size. The empty term \texttt{[]} consumes
some value \texttt{inp} and produces a stack of same size, acting as
an identity program. Note also that it has no premise, so it can be
considered a type-theoretical axiom.

The other three constructors are parameterized by a previous
\texttt{Term} value, representing the premise of each typing rule.
This \texttt{Term} representation should be understood is as
follows. When considering \texttt{Term 2 1} as a type alone,
\texttt{2} and \texttt{3} represent the input and output stack sizes
respectfully. Within the context of a constructor with a \texttt{Term}
premise, the ``output'' position of the premise represents that word's
\textit{precondition} while the ``output'' position of the conclusion
represent's the word's \textit{postcondition}.

The \texttt{true} rule states that if we have some term which consumes some
value \texttt{inp}, and produces another arbitrary value \texttt{out},
then the conclusion allows us to infer the existence of another term
which has the same input and one additional output. In other words,
\texttt{true} has a precondition that will always hold and a
postcondition stating that the value in the precondition will be
incremented by one.

In the \texttt{not} rule the premise's precondition requires that the previous output
be more than just any arbitrary \texttt{out}. Instead, the previous output
stack size must be at least one, but can be greater. Because the
\texttt{out} parameter was given in braces, Agda treats this as an
implicit argument that can be unified/inferred according to other
types in context. In this way, \texttt{1 + out} can represent several
values such as \texttt{1 + 0} or \texttt{1 + 7}. The conclusion of
\texttt{not} allows us to infer the existence of the another term of
output stack size \texttt{1 + out}. This fits with our informal mental
model of \texttt{not} requiring at least one argument to pop off the
stack, and pushing the logical negation back on.

Finally, \texttt{and} follows the same pattern except it requires at
least two values and produces just one, leaving the output stack size exactly
one less than what it was previously.

As typing derivations, our previous list-based terms look like
the following (note that we have overloaded the constructors of the
\texttt{Word} and \texttt{Term} types).

\begin{verbatim}
  notNot : Term 1 1
  notNot = not (not [])

  anotherTrue : Term 0 1
  anotherTrue = not (not (true []))

  nand : Term 2 1
  nand = not (and [])

  andAnd : Term 3 1
  andAnd = and (and [])
\end{verbatim}

Our terms now have the extra consumption/production values in their
type. The \texttt{andAnd} term shows how the representation correctly
composes the types of several terms. The first \texttt{and} requires
two values and produces one, which satisfies one of the second
\texttt{and}'s requirements, resulting in a final type of
\texttt{Term 3 1}.

We can highlight that the input stack remains constant throughout
subterms with an exploded view of each of the subterms in
\texttt{andAnd}.

\begin{verbatim}
  a : Term 3 3
  a = []

  b : Term 3 2
  b = and a

  c : Term 3 1
  c = and b
\end{verbatim}

\subsection{Syntactic Non-Uniqueness}

To avoid confusion, we will point out that in our representation
multiple syntactically identical terms can have different
types. Specifically, what can change is the original number of
arguments on the stack that the bottommost empty constructor provides.

\begin{verbatim}
  empty : Term 42 42
  empty = []

  nand' : Term 6 5
  nand' = not (and [])

  andAnd' : Term 10 8
  andAnd' = and (and [])
\end{verbatim}

Being able to represent multiple different types with a
syntatictically identical subterm is a property that we will later
exploit when defining functions to safely split and recombine terms
for crossover.

\subsection{Generic Terms}

When writing functions over term types, it would be tedious to provide
a case for every word in the language. Correspondingly, we will
extract the common parts among the constructors of our language into a
generic term.

\begin{verbatim}
  pre  : Word → ℕ → ℕ
  pre  true  n =     n
  pre  not   n = 1 + n
  pre  and   n = 2 + n

  post : Word → ℕ → ℕ
  post true  n = 1 + n
  post not   n = 1 + n
  post and   n = 1 + n

  data Term (inp : ℕ) : ℕ → Set where
    []  : Term inp inp

    _::_ : {n : ℕ} (w : Word) →
      Term inp (pre w n) →
      Term inp (post w n)
\end{verbatim}

Just like a \texttt{List} or a \texttt{Vec}, our new \texttt{Term} now
only has an empty case and a cons (\texttt{\_::\_}) case. Now we can
rewrite our examples to look just like their \texttt{List}
counterparts, except with the extra useful consumption/production
natural numbers in their types.

\begin{verbatim}
  notNot : Term 1 1
  notNot = not :: not :: []

  anotherTrue : Term 0 1
  anotherTrue = not :: not :: true :: []

  nand : Term 2 1
  nand = not :: and :: []

  andAnd : Term 3 1
  andAnd = and :: and :: []
\end{verbatim}

\section{Evaluation Function}

When comparing relative performance between evolved terms, one
typically needs to evaluate them to determine fitness . We will
proceed to write an evaluation function for the example language we
have used so far. Rest soundly knowing that Agda will perform a termination and
coverage check to prove the totality of functions. Notice that the
example below has a case for every possible term and input vector, and
uses the structurally smaller tail of the input term in recursive
calls.

\begin{verbatim}
  eval : {inp out : ℕ} → Term inp out → Vec Bool inp →
    Vec Bool out
  eval [] is = is
  eval (true :: xs) is = true :: eval xs is
  eval (false :: xs) is = false :: eval xs is
  eval (not :: xs) is with eval xs is
  ... | o :: os = ¬ o :: os
  eval (and :: xs) is with eval xs is
  ... | o₂ :: o₁ :: os = (o₁ ∧ o₂) :: ns
  eval (or :: xs) is with eval xs is
  ... | o₂ :: o₁ :: os = (o₁ ∨ o₂) :: os
\end{verbatim}

In addition to the term to evaluate, \texttt{eval} takes a vector of
booleans \footnote{Do not get confused by the true/false constructors
  of the \texttt{Bool} type and \texttt{Term} types. Agda can
  differentiate between overloaded constructor names according to the
  type they have in context.}
whose length \texttt{inp} is equal to the number of inputs the
term expects. The return type of the function is another vector of
bools \texttt{out}, matching the evaluated term's output. Both of these
properties are of course enforced statically, giving more assurance that
our algorithm is doing what we expect.

\section{Genetic Operators}

When writing genetic operators, for example
Tchnernev's \cite{tchernev:forthcross} 1-point crossover, we need to take
subsections of different terms and recombine them in a safe
matter. Tchernev points out that we need to split parent terms at a
point of equal output stacks to achieve safe recombination. But,
what is the criterion for a safe append of two arbitrary terms after
they have been split in this manner?

\subsection{Transitive Append}

Terms may have different initial input stacks, and produce
different outputs according to their contained words. A safe append
of two terms illustrates the transitive property. 

\begin{verbatim}
  _++_ : {inp mid out : ℕ} →
    Term mid out → Term inp mid →
    Term inp out
  [] ++ ys = ys
  (x :: xs) ++ ys = x :: (xs ++ ys)

  bc : Term 2 1
  bc = and :: []

  ab : Term 3 2
  ab = and :: []

  ac : Term 3 1
  ac = bc ++ ab
\end{verbatim}

If an attempt is made to append two terms whose input/output
requirements do not satisfy each other, a compile error will
occur. Using a function with a such an informative type gives a high
degree of confidence that we are doing the right thing when used
inside another function such as crossover. In fact, as we shall soon
see the type of this function gives us more than just confidence.

\subsection{Transitive Split}

Now that we have a function to safely recombine terms in a transitive
way, we need to come up with a compatible way to split a crossover
parent. In DTP a \textit{view} \cite{mcbride:viewleft} is a general technique for using a
specialized type to reveal structure about another type. In our case
we want to view a term as another type representing the two
subsections it was split at. The following is a derivative of the
\texttt{TakeView} type in \cite{oury:tpop}.

\begin{verbatim}
  data Split {inp out : ℕ} (mid : ℕ) :
    Term inp out → Set where
    _++'_ :
      (xs : Term mid out)
      (ys : Term inp mid) →
      Split B (xs ++ ys)
\end{verbatim}

The type above captures exactly how we would like split terms to be
represented such that they can be transitively recombined. The
\texttt{mid} natural number index reveals the satisfied
pre/post condition point a term was split at, and the term index is the
value we are splitting. The constructor carries the two
subterms which share \texttt{mid} in a way that the resulting type can
recombine the two via \texttt{xs ++ ys}.

Given two parent terms split in such a way, crossover needs to produce
two offspring that swap the subterms at the splits. Functions for both
of these swaps can be straightforwardly defined.

\begin{verbatim}
  swap₁ : {inp mid out : ℕ} {xs ys : Term inp out} →
    Split mid xs → Split mid ys → Term inp out
  swap₁ (xs ++' ys) (as ++' bs) = xs ++ bs

  swap₂ : {inp mid out : ℕ} {xs ys : Term inp out} →
    Split mid xs → Split mid ys → Term inp out
  swap₂ (xs ++' ys) (as ++' bs) = as ++ ys
\end{verbatim}

\subsubsection{Dependent Pairs}

Given some term and a natural number, we would like to split the term
at the point indexed into. This function will be the key component of
determining the split in the female parent of
crossover. \texttt{Split} is specific enough to tell us the shared
\texttt{mid} between the two subterms. However, for the purposes of this
function we do not care what \texttt{mid} is (actually, we would like
the function to tell us what it is.)

\begin{verbatim}
  data Σ (A : Set) (B : A → Set) : Set where
    _,_ : (x : A) → B x → Σ A B
\end{verbatim}

A non-dependent pair, or tuple, carries 2 values of arbitrary
types. In the dependent version of pairs, the \textit{value} in the first
component is used to determine the \textit{type} in the second
component. One dependently typed programming technique is using a
dependent pair to hide the index type of a return value when you don't
know or care what it will be. For example, sometimes we would merely
like to write down a vector value and have the compiler figure out the
unique possible length.

\begin{verbatim}
  specifiedLength : Σ ℕ (λ n → Vec Bool n)
  specifiedLength = 3 , true :: false :: true :: []

  discoveredLength : Σ ℕ (λ n → Vec Bool n)
  discoveredLength = _ , true :: false :: true :: []
\end{verbatim}

Note the use of an anonymous function in the type. Remember that in DTP
we can do anything at the type level that we can do at the value
level, including the use of the intimately known $\lambda$. With this
dependent pair trick up our sleeves, we can define \texttt{split}.

\begin{verbatim}
  split : {inp out : ℕ} (n : ℕ) (xs : Term inp out) →
    Σ ℕ (λ mid → Split mid xs)
  split   zero  xs = _ , [] ++' xs
  split (suc n) [] = _ , [] ++' []
  split (suc n) (x :: xs) with split n xs
  split (suc n) (x :: ._) | _ , xs ++' ys =
    _ , (x :: xs) ++' ys
\end{verbatim}

Because we are returning a \texttt{Split} value, the split will always
hold two subterms that can be transitively combined to produce the
original. This way, splitting \texttt{andAnd} results in two
\texttt{and :: []} values of type \texttt{Term 2 1} and
\texttt{Term 3 2}, rather than anything else.

\subsection{Type-Preserving Crossover}

With the previous types and functions defined, defining a
crossover function that takes two parent terms of the same type and
returns two child terms of the same type is not far away.

\subsubsection{Split Female}

For the first step in 1-point crossover we need to split the first
parent (referred to here as the female) at some random point. Thus, we
need to know the length of the female, then choose a random number
bounded by that length.

\begin{verbatim}
  length : {inp out : ℕ} → Term inp out → ℕ
  length [] = 0
  length (x :: xs) = suc (length xs)

  splitFemale : {inp out : ℕ} (xs : Term inp out) → ℕ →
    Σ ℕ (λ mid → Split mid xs)
  splitFemale xs rand with rand mod (suc (length xs))
  ... | i = split (toℕ i) xs
\end{verbatim}

Note that we use a \texttt{\_mod\_} function which returns a finite set
representing the modulus of its two arguments. The definition of this
function can be found in the supplementary source code, as it is not
particularly relevant to what we would like to explain.

Based upon the \texttt{mid} index at which the female was split, the
male split can be determined by choosing a random member of all
possible compatible splits.

\begin{verbatim}
  splits : {inp out : ℕ} (n mid : ℕ) (xs : Term inp out) →
    Σ ℕ (λ n → Vec (Split mid xs) n)
  splits zero mid xs with split zero xs
  ... | mid' , ys with mid =? mid'
  ... | yes p rewrite p = _ , ys :: []
  ... | no _ = _ , []
  splits (suc n) mid xs with split (suc n) xs
  ... | mid' , ys with mid =? mid' | splits n mid xs
  ... | yes p | _ , yss rewrite p = _ , ys :: yss
  ... | no _ | _ , yss = _ , yss
\end{verbatim}

\subsubsection{Propositional Equality}

In the definition of \texttt{splits} we simultaneously split at all
possible positions of the male term, and filter out ones that would
not be compatible with respect to transitively appending them back
together.

It is intuitive that in the algorithm we must compare the target \texttt{mid}
that we are splitting on and the \texttt{mid'} in the current
split. Normally a comparison of two terms is performed by passing them
to a function that returns a boolean value, then doing something
different for the true and false cases. While a boolean value is
enough to convince a certain kind of person that action should be
taken, it is not enough to convince a type checker.

Consider the \texttt{yes p} case (analogous to a typical \texttt{true}
case) within the \texttt{splits zero} case. We would like to return
our freshly split \texttt{ys} value, but the type checker won't have
it. Why not? If we look at the type signature of \texttt{splits}, it
requires a \texttt{Split mid xs}, but \texttt{ys} is a \texttt{Split mid'
  xs}. Luckily the \texttt{=?} comparison function returned something
more than just a boolean, but a constructive proof that both compared
values were in fact the same. We pass the proof \texttt{p} (pattern
matched as \texttt{yes p}) to Agda's \texttt{rewrite} keyword to
convince the type checker that \texttt{ys : Split mid' xs} is acceptable
because \texttt{mid ≡ mid'}.

What should you take away from all this? Mainly that the type checker
requires formal constructive evidence in order to enforce
invariants you prescribe. This evidence is in practice easy to work
with, as it is made of ordinary dependent types like everything
else. The payoff is confidence; the burden of verifying that
a program behaves as it is expected to is lifted from the programmer's
shoulders and onto the type checker's.

\subsubsection{Split Male}

When we split the male parent we choose a random member of the
type-correct splits. However, this function returns a value of type
\texttt{Maybe}, so that it may return \texttt{nothing} if there is no
compatible split at all.

\begin{verbatim}
  splitMale : {inp out : ℕ} (xs : Term inp out) →
    (mid rand : ℕ) → Maybe (Split mid xs)
  splitMale xs mid rand
    with splits (length xs) mid xs
  ... | zero , [] = nothing
  ... | suc n , xss
    = just (lookup (rand mod suc n) xss)
\end{verbatim}

Note that the proof complexity in the implementation of
\texttt{splits} is isolated. Once we have a function definition that
typechecks, we can freely use it without having to do any work over
again.

Finally, we can write \texttt{crossover} to combine the female and
male splits, and return both children using the \texttt{swap}s defined
earlier.

\begin{verbatim}
  crossover : {inp out : ℕ}
    (female male : Term inp out) (randF randM : ℕ) →
    Term inp out × Term inp out
  crossover female male randF randM
    with splitFemale female randF
  ... | mid , xs with splitMale male mid randM
  ... | nothing = female , male
  ... | just ys = swap₁ xs ys , swap₂ xs ys
\end{verbatim}

In the case where no valid male swap existed, we return the original
two parents.

\section{Conclusion}

Dependent types can be used to enforce desired invariants by using
informative data types and function type signatures. We have shown
some basics for creating a verified stack-based GP implementation
using type-safe 1-point crossover.

By building on a verified base, more complex GP algorithms can be
created, and evolutionary data can be analyzed with much greater
confidence that implementation bugs did not affect GP run behavior.

Hopefully the examples presented herein can serve as a template to
assist authors in encoding invariants for their particular flavors of
GP within the context of dependently typed programming.

\bibliographystyle{abbrv}
\bibliography{aaip}

\end{document}
